Lab 3, submitted week 4:
nhaas_lab3

set hive.cli.print.header=true;


Compare the following query's run time in HIVE and Spark 
SELECT
    user_id,
    COUNT(user_id) AS log_count 
FROM weblogs_schema
GROUP BY user_id
ORDER BY log_count DESC
LIMIT 50;


HIVE
Time taken: 118.867 seconds, Fetched: 50 row(s)

Spark 
Time taken: 28.458 seconds, Fetched 50 row(s)

Spark - Parquet
Time taken: 8.861 seconds, Fetched 50 row(s)

1.List the execution time of the weblog aggregation query for Hive, SparkSQL, and SparkSQL on Parquet.


	HIVE
	Time taken: 118.867 seconds, Fetched: 50 row(s)

	Spark 
	Time taken: 28.458 seconds, Fetched 50 row(s)

	Spark - Parquet
	Time taken: 8.861 seconds, Fetched 50 row(s)

2.How many jobs does Hive launch? Does SparkSQL launch jobs?


	HIVE launches two jobs for this query, one is the map job and one is the reduce job. 

	If Spark SQL runs any jobs, they are not visible to me.  Spark does not use a Map Reduce framework; it uses Scala. I do not expect to see any jobs launched for Spark.

3. Write a query which joins weblogs_parquet to user_info and counts the top 5 locations. List the locations.

SELECT
u.location,
count(u.location) loc_count
from 
weblogs_parquet w
join
user_info u
on w.user_id = u.user_id
GROUP BY u.location
ORDER BY loc_count DESC
LIMIT 5;


location 	loc_count
La Fayette	49                                                              
Leeds	47
Blountsville	46
Hayden	45
Hamilton	45
Time taken: 9.098 seconds, Fetched 5 row(s)



